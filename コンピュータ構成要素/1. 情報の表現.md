# 情報の表現

## 情報量の表現

- コンピュータ内部では全ての情報は「0」と「1」で表現される
- 2 進数 1 桁 = ビット
  - n ビットで 2^n 通りの情報を表現できる
- 8 ビット = 1 バイト

| 接頭語         | Byte 数 |
| -------------- | ------- |
| m ( ミリ )     | 10^-3   |
| μ ( マイクロ ) | 10^-6   |
| n ( ナノ )     | 10^-9   |
| p ( ピコ )     | 10^-12  |
| K              | 10^3    |
| M              | 10^6    |
| G              | 10^9    |
| T              | 10^12   |

## 文字の表現

コンピュータの内部は「0」と「1」でしか構成されていないのになぜ文字を扱うことができるのか？

- → 文字一つ一つを「0」「1」で表した識別番号（文字コード）を割り振っているから

### 文字コードには色々種類がある

- ASCII コード (米国標準符号で最も基本となる文字コード)
  - **American Standard Code** for Information Interchange
- シフト JS コード（主に DOS や Windows）
- EUC (Extended UNIX Code、主に UNIX）
- Unicode

作成者が使った文字コードと異なる文字コードを当てはめると「文字化け」が起こる。

### Unicode について

#### Unicode って何？

- 世界中の文字コードを統一して扱えるようにした文字コード
- Unicode を符号化する方式が UTF-8 とか UTF-16 とか UTF-32
- 16 進数で表現する

#### Unicode が生まれた背景

- いっぱい文字コードがあって、英語ともう 1 つの言語（日本語や中国語など）を使うくらいならいけるけど更に多くの言語を使おうとすると大変だった
- 文字化けしないように文字コードに合わせてプログラムをいちいち修正する必要があり面倒臭かった

#### てか符号化方式って何？

- 文字集合をどういうバイト列で表現するかのこと

### これをざっと読みました。難しい

[Unicode とは？ その歴史と進化、開発者向け基礎知識](https://www.buildinsider.net/language/csharpunicode/01)

#### へえ〜と思ったこと

##### UTF-8 において日本語(全角文字)が 2Byte で半角文字が 1Byte である理由

- もともと ASCII で 256 通り（1 バイト）の文字が表現されていた
- Unicode で表現するときに ASCII 以外の文字を表現しなきゃいけなかった
- 2 バイト = 2^16 = 65536 通りで表現した
- でも、２バイト固定にしちゃうと元々 ASCII を使ってた人たちはテキストファイルのサイズが 2 倍になっちゃう
- ASCII との互換は重要なので（American Standard だから）、ASCII と互換性のある符号化方式 = UTF-8 が生まれた
- UTF-8 において ASCII 文字は 1Byte, それ以外は 2〜4Byte で表現される
- 実際には日本語（全角文字）全部が 2Byte なわけではない

##### サロゲートペアの話

- 元々 Unicode は 2Byte 固定にしようと思ってた
- 古語とかも含めると世界中には色んな文字があるので 2Byte じゃ全然足りなかった
- そこで「Unicode 1.1 の時点でまだ使っていない領域を、2 文字 1 組にして、最大で 21bits の 1 つのコードポイントを表現するために使う」というルールを定めた
- 例えば「村」だったら「木」「寸」の 2 文字と認識するみたいな感じ
- 21bits の文字は UTF-8 では 4Byte で表現される
- こいつのせいで UTF-8 は 1〜4Byte の可変長コードになった
